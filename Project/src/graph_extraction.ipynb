{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for extracting graph from tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extracted data in /data/drug_interactions.tsv with the following fields:\n",
    "\n",
    "- drug_interaction_id: id of drug A\n",
    "- name: name of drug A\n",
    "- description: interaction info of drug A with drug B\n",
    "- drugbank_id: id of drug B\n",
    "\n",
    "Now we want to extract a graph with nodes as the drugs and edges between each drug_interaction_id-drugbank_id pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://a61e81c06b19:4040\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1603063223840)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.rdd.RDD[String] = /home/jovyan/work/data/drug_interactions.tsv MapPartitionsRDD[1] at textFile at <console>:30\n",
       "header: String = drug_interaction_id\tname\tdescription\tdrugbank_id\n",
       "data: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at filter at <console>:33\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read in data \n",
    "val lines = sc.textFile(\"/home/jovyan/work/data/drug_interactions.tsv\")\n",
    "// skip header\n",
    "val header = lines.first() // extract header\n",
    "val data = lines.filter(row => row != header) // filter out header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Array[String] = Array(DB06605\tApixaban\tApixaban may increase the anticoagulant activities of Lepirudin.\tDB00001, DB06695\tDabigatran etexilate\tDabigatran etexilate may increase the anticoagulant activities of Lepirudin.\tDB00001)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at map at <console>:31\n",
       "drugs: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[7] at distinct at <console>:32\n",
       "drugsWIndex: org.apache.spark.rdd.RDD[((String, String), Long)] = ZippedWithIndexRDD[8] at zipWithIndex at <console>:33\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lines = data.map(line => line.split(\"\\t\"))\n",
    "val drugs = lines.map(line => (line(0), line(1))).distinct()\n",
    "val drugsWIndex = drugs.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res38: Array[Array[String]] = Array(Array(DB06605, Apixaban, Apixaban may increase the anticoagulant activities of Lepirudin., DB00001), Array(DB06695, Dabigatran etexilate, Dabigatran etexilate may increase the anticoagulant activities of Lepirudin., DB00001), Array(DB01254, Dasatinib, The risk or severity of bleeding and hemorrhage can be increased when Dasatinib is combined with Lepirudin., DB00001), Array(DB01609, Deferasirox, The risk or severity of gastrointestinal bleeding can be increased when Lepirudin is combined with Deferasirox., DB00001), Array(DB01586, Ursodeoxycholic acid, The risk or severity of bleeding and bruising can be increased when Lepirudin is combined with Ursodeoxycholic acid., DB00001))\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[(String, String)] = Array((DB00492,Fosinopril), (DB04826,Thenalidine), (DB01395,Drospirenone), (DB13557,Thiopropazate))\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[((String, String), Long)] = Array(((DB00492,Fosinopril),0), ((DB04826,Thenalidine),1), ((DB01395,Drospirenone),2), ((DB13557,Thiopropazate),3))\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugsWIndex.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// each vertex: (drug_interaction_id of drug A, (name of drug A))\n",
    "// TODO could add some more info here to each vertex like number of drugs it interacts with, protein bindings etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertexRDD: org.apache.spark.rdd.RDD[(Long, (String, String))] = MapPartitionsRDD[112] at map at <console>:30\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertexRDD = drugsWIndex.map(drug => (drug._2, drug._1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res47: Array[(Long, (String, String))] = Array((0,(DB00492,Fosinopril)))\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertexRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "originalDrugIDs: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[26] at zipWithIndex at <console>:30\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val originalDrugIDs = lines.map(line => line(0)).zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res24: Array[(String, Long)] = Array((DB06605,0))\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDrugIDs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactionDrugIDs: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[24] at zipWithIndex at <console>:31\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// join interaction IDs with vertexArray\n",
    "val interactionDrugIDs = lines.map(line => line(3)).zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res23: Array[(String, Long)] = Array((DB00001,0))\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactionDrugIDs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drug2NodeMap: org.apache.spark.rdd.RDD[(String, Long)] = MapPartitionsRDD[11] at map at <console>:30\n",
       "res9: Array[(String, Long)] = Array((DB00492,0))\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drug2NodeMap = drugsWIndex.map(drug => (drug._1._1, drug._2))\n",
    "drug2NodeMap.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugBids: org.apache.spark.rdd.RDD[(Long, (String, Long))] = ShuffledRDD[70] at sortByKey at <console>:37\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TODO map interactionDrugIDs to nodeIDs using map from drug IDs to node IDs\n",
    "val drugBids = drug2NodeMap.join(interactionDrugIDs)\n",
    "                         .map(x => (x._2._2, (x._1, x._2._1)))\n",
    "                         .sortByKey() // original order of drug interactions in original dataset, key is index used to identify order (added using zipWithIndex to interactionDrugIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res32: Array[(Long, (String, Long))] = Array((0,(DB00001,3022)), (1,(DB00001,3022)), (2,(DB00001,3022)), (3,(DB00001,3022)), (4,(DB00001,3022)))\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugBids.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugAids: org.apache.spark.rdd.RDD[(Long, (String, Long))] = ShuffledRDD[77] at sortByKey at <console>:37\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TODO map interactionDrugIDs to nodeIDs using map from drug IDs to node IDs\n",
    "val drugAids = drug2NodeMap.join(originalDrugIDs)\n",
    "                         .map(x => (x._2._2, (x._1, x._2._1)))\n",
    "                         .sortByKey() // original order of drug interactions in original dataset, key is index used to identify order (added using zipWithIndex to interactionDrugIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res39: Array[(Long, (String, Long))] = Array((0,(DB06605,220)), (1,(DB06695,2363)), (2,(DB01254,3253)), (3,(DB01609,2748)), (4,(DB01586,448)))\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugAids.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res36: Array[(String, Long)] = Array((DB06605,0), (DB06695,1), (DB01254,2), (DB01609,3), (DB01586,4))\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDrugIDs.take(5) // matches with above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edgeData: org.apache.spark.rdd.RDD[(Long, ((String, Long), (String, Long)))] = ShuffledRDD[89] at sortByKey at <console>:33\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val edgeData = drugAids.join(drugBids)\n",
    "                        .sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res41: Array[(Long, ((String, Long), (String, Long)))] = Array((0,((DB06605,220),(DB00001,3022))), (1,((DB06695,2363),(DB00001,3022))), (2,((DB01254,3253),(DB00001,3022))), (3,((DB01609,2748),(DB00001,3022))), (4,((DB01586,448),(DB00001,3022))))\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgeData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edgeRDD: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[String]] = MapPartitionsRDD[99] at map at <console>:35\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Now we have the Node IDs for each drugA-drugB interaction,\n",
    "// let's populate edge array for each interaction (row in tsv). \n",
    "val edgeRDD =  edgeData.map(x => x._2)\n",
    "                    .map(x => Edge(x._1._2 , x._2._2, \"interaction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res46: Array[org.apache.spark.graphx.Edge[String]] = Array(Edge(220,3022,interaction), Edge(2363,3022,interaction), Edge(3253,3022,interaction), Edge(2748,3022,interaction), Edge(448,3022,interaction))\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgeRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph: org.apache.spark.graphx.Graph[(String, String),String] = org.apache.spark.graphx.impl.GraphImpl@36582ef0\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create graph\n",
    "val graph = Graph(vertexRDD, edgeRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "// save vertices and edges\n",
    "graph.vertices.saveAsTextFile(\"/home/jovyan/work/data/vertices.txt\")\n",
    "graph.edges.saveAsTextFile(\"/home/jovyan/work/data/edges.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
