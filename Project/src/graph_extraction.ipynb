{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting graph edges and nodes from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first section uses a dataset we extracted with no node features.\n",
    "We have extracted data in /data/drug_interactions.tsv with the following fields:\n",
    "\n",
    "- drug_interaction_id: id of drug A\n",
    "- name: name of drug A\n",
    "- description: interaction info of drug A with drug B\n",
    "- drugbank_id: id of drug B\n",
    "\n",
    "Now we want to extract a graph with nodes as the drugs and edges between each drug_interaction_id-drugbank_id pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.rdd.RDD[String] = /home/jovyan/work/data/drug_interactions.tsv MapPartitionsRDD[283] at textFile at <console>:38\n",
       "header: String = drug_interaction_id\tname\tdescription\tdrugbank_id\n",
       "data: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[284] at filter at <console>:41\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read in data \n",
    "val lines = sc.textFile(\"/home/jovyan/work/data/drug_interactions.tsv\")\n",
    "// skip header\n",
    "val header = lines.first() // extract header\n",
    "val data = lines.filter(row => row != header) // filter out header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Array[String] = Array(DB06605\tApixaban\tApixaban may increase the anticoagulant activities of Lepirudin.\tDB00001, DB06695\tDabigatran etexilate\tDabigatran etexilate may increase the anticoagulant activities of Lepirudin.\tDB00001)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lines: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at map at <console>:27\n",
       "res1: Array[Array[String]] = Array(Array(DB06605, Apixaban, Apixaban may increase the anticoagulant activities of Lepirudin., DB00001), Array(DB06695, Dabigatran etexilate, Dabigatran etexilate may increase the anticoagulant activities of Lepirudin., DB00001), Array(DB01254, Dasatinib, The risk or severity of bleeding and hemorrhage can be increased when Dasatinib is combined with Lepirudin., DB00001), Array(DB01609, Deferasirox, The risk or severity of gastrointestinal bleeding can be increased when Lepirudin is combined with Deferasirox., DB00001))\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lines = data.map(line => line.split(\"\\t\"))\n",
    "lines.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linesDrugs: org.apache.spark.rdd.RDD[String] = /home/jovyan/work/data/drug_features.csv MapPartitionsRDD[5] at textFile at <console>:30\n",
       "header: Array[String] = Array(DB06605, Apixaban, Apixaban may increase the anticoagulant activities of Lepirudin., DB00001)\n",
       "data: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[6] at filter at <console>:33\n",
       "res2: Array[String] = Array(drug_id\ttype\tgroup\tinteractions, DB00001\tbiotech\t[approved]\t[DB06605, DB06695, DB01254, DB01609, DB01586, DB02123, DB02659, DB02691, DB03619, DB04348, DB05990, DB06777, DB08833, DB08834, DB08857, DB11622, DB11789, DB09075, DB09053, DB08935, DB06228, DB06206, DB09070, DB00932, DB00013, DB00163, DB09030, DB01381, DB01181, DB00468, DB00908, DB00675, DB00539, DB00806, DB00686, DB00583, DB00255, DB00269, DB00286, DB0...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read in all drugs (drug_interactions.tsv doesn't contain all drugs, only those with interactions) to get all drugs\n",
    "val linesDrugs = sc.textFile(\"/home/jovyan/work/data/drug_features.csv\")\n",
    "// skip header\n",
    "val header = lines.first() // extract header\n",
    "val data = lines.filter(row => row != header) // filter out header\n",
    "linesDrugs.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+--------------------+\n",
      "|drug_id|   type|     group|        interactions|\n",
      "+-------+-------+----------+--------------------+\n",
      "|DB00001|biotech|[approved]|[DB06605, DB06695...|\n",
      "|DB00002|biotech|[approved]|[DB00012, DB00016...|\n",
      "|DB00003|biotech|[approved]|                null|\n",
      "+-------+-------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "all_drugs: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var all_drugs = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\"\\t\", \"header\"->\"true\"))\n",
    "  .csv(\"/home/jovyan/work/data/drug_features.csv\")\n",
    "all_drugs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distinct_drugs: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [drug_id: string]\n",
       "res2: Long = 13580\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val distinct_drugs = all_drugs.select(\"drug_id\").distinct()\n",
    "distinct_drugs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugs: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[32] at map at <console>:27\n",
       "res3: Array[String] = Array(DB00194, DB00741, DB00846, DB00912)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var drugs = distinct_drugs.select(\"drug_id\").rdd\n",
    "                    .map(x => x(0).toString) // prevent Array type\n",
    "drugs.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Long = 13580\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We produce a drug -> node map containing the drug id and node id (which will be used as input to our graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drug2NodeMap: org.apache.spark.rdd.RDD[(String, Long)] = ZippedWithIndexRDD[33] at zipWithIndex at <console>:26\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drug2NodeMap = drugs.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[(String, Long)] = Array((DB00194,0), (DB00741,1), (DB00846,2), (DB00912,3), (DB01357,4))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug2NodeMap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Long = 13580\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug2NodeMap.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_drug_node_map: org.apache.spark.sql.DataFrame = [drug_id: string, node_id: bigint]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_drug_node_map = spark.createDataFrame(drug2NodeMap).toDF(\"drug_id\", \"node_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// save map for later use\n",
    "df_drug_node_map\n",
    "   .repartition(1)\n",
    "   .write.format(\"com.databricks.spark.csv\")\n",
    "   .option(\"header\", \"true\")\n",
    "   .save(\"/home/jovyan/work/data/drug2NodeMap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to map drugs in out drug interactions dataset to these node IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----------+\n",
      "|drug_interaction_id|                name|         description|drugbank_id|\n",
      "+-------------------+--------------------+--------------------+-----------+\n",
      "|            DB06605|            Apixaban|Apixaban may incr...|    DB00001|\n",
      "|            DB06695|Dabigatran etexilate|Dabigatran etexil...|    DB00001|\n",
      "|            DB01254|           Dasatinib|The risk or sever...|    DB00001|\n",
      "|            DB01609|         Deferasirox|The risk or sever...|    DB00001|\n",
      "|            DB01586|Ursodeoxycholic acid|The risk or sever...|    DB00001|\n",
      "+-------------------+--------------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interactions_df: org.apache.spark.sql.DataFrame = [drug_interaction_id: string, name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var interactions_df = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\"\\t\", \"header\"->\"true\"))\n",
    "  .csv(\"/home/jovyan/work/data/drug_interactions.tsv\")\n",
    "interactions_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactions_rdd: org.apache.spark.rdd.RDD[(org.apache.spark.sql.Row, Long)] = ZippedWithIndexRDD[58] at zipWithIndex at <console>:26\n",
       "res9: Array[(org.apache.spark.sql.Row, Long)] = Array(([DB06605,Apixaban,Apixaban may increase the anticoagulant activities of Lepirudin.,DB00001],0))\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var interactions_rdd = interactions_df.rdd.zipWithIndex()\n",
    "interactions_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactions_rdd2: org.apache.spark.rdd.RDD[(String, String, String, String, Long)] = MapPartitionsRDD[59] at map at <console>:26\n",
       "res10: Array[(String, String, String, String, Long)] = Array((DB06605,Apixaban,Apixaban may increase the anticoagulant activities of Lepirudin.,DB00001,0))\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val interactions_rdd2 = interactions_rdd.map(x => (x._1(0).toString, x._1(1).toString, x._1(2).toString, x._1(3).toString, x._2))\n",
    "interactions_rdd2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----------+----------+\n",
      "|drug_interaction_id|                name|         description|drugbank_id|row_number|\n",
      "+-------------------+--------------------+--------------------+-----------+----------+\n",
      "|            DB06605|            Apixaban|Apixaban may incr...|    DB00001|         0|\n",
      "|            DB06695|Dabigatran etexilate|Dabigatran etexil...|    DB00001|         1|\n",
      "|            DB01254|           Dasatinib|The risk or sever...|    DB00001|         2|\n",
      "+-------------------+--------------------+--------------------+-----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "interactions_df: org.apache.spark.sql.DataFrame = [drug_interaction_id: string, name: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df = spark.createDataFrame(interactions_rdd2).toDF(\"drug_interaction_id\", \"name\", \"description\", \"drugbank_id\", \"row_number\")\n",
    "interactions_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|drug_interaction_id|row_number|\n",
      "+-------------------+----------+\n",
      "|            DB06605|         0|\n",
      "|            DB06695|         1|\n",
      "+-------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "drugAs: org.apache.spark.sql.DataFrame = [drug_interaction_id: string, row_number: bigint]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drugAs = interactions_df.select(\"drug_interaction_id\", \"row_number\")\n",
    "drugAs.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: Long = 2668185\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugAs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugAWithNodeIDs: org.apache.spark.sql.DataFrame = [drug_interaction_id: string, row_number: bigint ... 2 more fields]\n",
       "res14: Long = 2668185\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var drugAWithNodeIDs = drugAs.join(df_drug_node_map, $\"drug_interaction_id\" === $\"drug_id\", \"left\")\n",
    "drugAWithNodeIDs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+\n",
      "|drug_A_id|row_number|drug_A_node_id|\n",
      "+---------+----------+--------------+\n",
      "|  DB00194|    315697|             0|\n",
      "|  DB00741|      1855|             1|\n",
      "|  DB00741|     13266|             1|\n",
      "+---------+----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "drugAWithNodeIDs: org.apache.spark.sql.DataFrame = [drug_A_id: string, row_number: bigint ... 1 more field]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugAWithNodeIDs = drugAWithNodeIDs.withColumnRenamed(\"drug_interaction_id\",\"drug_A_id\")\n",
    "           .withColumnRenamed(\"node_id\",\"drug_A_node_id\").drop(\"drug_id\")\n",
    "drugAWithNodeIDs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugBs: org.apache.spark.sql.DataFrame = [drugbank_id: string, row_number: bigint]\n",
       "drugBWithNodeIDs: org.apache.spark.sql.DataFrame = [drugbank_id: string, row_number: bigint ... 1 more field]\n",
       "res16: Long = 2668185\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val drugBs = interactions_df.select(\"drugbank_id\", \"row_number\")\n",
    "var drugBWithNodeIDs = drugBs.join(df_drug_node_map, $\"drugbank_id\" === $\"drug_id\", \"left\")\n",
    "                        .withColumnRenamed(\"node_id\",\"drug_B_node_id\").drop(\"drug_id\")\n",
    "drugBWithNodeIDs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+\n",
      "|drugbank_id|row_number|drug_B_node_id|\n",
      "+-----------+----------+--------------+\n",
      "|    DB00194|     77879|             0|\n",
      "+-----------+----------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drugBWithNodeIDs.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edgesData: org.apache.spark.sql.DataFrame = [row_number: bigint, drug_A_id: string ... 3 more fields]\n",
       "res18: Long = 2668185\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// join drugAWithNodeIDs and drugBWithNodeIDs to get the edges\n",
    "var edgesData = drugAWithNodeIDs.join(drugBWithNodeIDs, Seq(\"row_number\"), \"left\")\n",
    "edgesData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+--------------+\n",
      "|drug_A_id|drug_A_node_id|drugbank_id|drug_B_node_id|\n",
      "+---------+--------------+-----------+--------------+\n",
      "|  DB09030|         10315|    DB00001|          9529|\n",
      "|  DB00468|          4259|    DB00001|          9529|\n",
      "|  DB00056|            61|    DB00001|          9529|\n",
      "+---------+--------------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgesData = edgesData.drop(\"row_number\")\n",
    "edgesData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "// save edges data for later use\n",
    "edgesData\n",
    "   .repartition(1)\n",
    "   .write.format(\"com.databricks.spark.csv\")\n",
    "   .option(\"header\", \"true\")\n",
    "   .save(\"/home/jovyan/work/data/edges.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph extraction with Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use GCNs for link prediction, we need to extract some features for each node (drug). \n",
    "For this part, we use a dataset /data/drug_features.csv with the following fields:\n",
    "\n",
    "    - drug_id: id of drug \n",
    "    - type: name of drug A\n",
    "    - group: interaction info of drug A with drug B\n",
    "    - target_info: list of info extracted directly from xml, needed for extracting target gene name(s)\n",
    "    - enzyme_info: list of info extracted directly from xml, needed for extracting enzyme gene name(s)\n",
    "    - interactions: list of all drug ids this drug interacts with\n",
    "\n",
    "Now we want to extract a graph with nodes as the drugs containing features, and edges between each drug_interaction_id-drugbank_id pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+--------------------+\n",
      "|drug_id|          type|               group|        interactions|\n",
      "+-------+--------------+--------------------+--------------------+\n",
      "|DB00001|       biotech|          [approved]|[DB06605, DB06695...|\n",
      "|DB00002|       biotech|          [approved]|[DB00012, DB00016...|\n",
      "|DB00003|       biotech|          [approved]|                null|\n",
      "|DB00004|       biotech|[approved, invest...|[DB00012, DB00016...|\n",
      "|DB00005|       biotech|[approved, invest...|[DB01281, DB00026...|\n",
      "|DB00006|small molecule|[approved, invest...|[DB06605, DB06695...|\n",
      "|DB00007|small molecule|[approved, invest...|[DB09066, DB09083...|\n",
      "|DB00008|       biotech|[approved, invest...|[DB06643, DB00005...|\n",
      "+-------+--------------+--------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\"\\t\", \"header\"->\"true\"))\n",
    "  .csv(\"/home/jovyan/work/data/drug_features.csv\")\n",
    "df.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.OneHotEncoder\n",
       "import org.apache.spark.ml.feature.StringIndexer\n",
       "import org.apache.spark.ml.feature.VectorIndexer\n",
       "import org.apache.spark.ml.feature.CountVectorizerModel\n",
       "import org.apache.spark.sql.SparkSession\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.OneHotEncoder\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.feature.VectorIndexer\n",
    "import org.apache.spark.ml.feature.CountVectorizerModel\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. type feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          type|\n",
      "+--------------+\n",
      "|          null|\n",
      "|       biotech|\n",
      "|small molecule|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// let's see what values we have here\n",
    "df.select(\"type\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+--------------------+----------+-----------------+\n",
      "|drug_id|          type|               group|        interactions|is_biotech|is_small_molecule|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+\n",
      "|DB00001|       biotech|          [approved]|[DB06605, DB06695...|      true|            false|\n",
      "|DB00002|       biotech|          [approved]|[DB00012, DB00016...|      true|            false|\n",
      "|DB00003|       biotech|          [approved]|                null|      true|            false|\n",
      "|DB00004|       biotech|[approved, invest...|[DB00012, DB00016...|      true|            false|\n",
      "|DB00005|       biotech|[approved, invest...|[DB01281, DB00026...|      true|            false|\n",
      "|DB00006|small molecule|[approved, invest...|[DB06605, DB06695...|     false|             true|\n",
      "|DB00007|small molecule|[approved, invest...|[DB09066, DB09083...|     false|             true|\n",
      "|DB00008|       biotech|[approved, invest...|[DB06643, DB00005...|      true|            false|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 4 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// add is_biotech (0/1) and is_small_molecule columns\n",
    "df = df.withColumn(\"is_biotech\", col(\"type\") === \"biotech\")\n",
    "df = df.withColumn(\"is_small_molecule\", col(\"type\") === \"small molecule\")\n",
    "df.show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. group feature\n",
    "This feature is a list of values from: ['withdrawn', 'illicit', 'vet_approved', 'investigational', 'approved', 'experimental', 'nutraceutical'] (extracted using pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "|drug_id|          type|               group|        interactions|is_biotech|is_small_molecule|withdrawn|illicit|vet_approved|investigational|approved|experimental|nutraceutical|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "|DB00001|       biotech|          [approved]|[DB06605, DB06695...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00002|       biotech|          [approved]|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00003|       biotech|          [approved]|                null|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00004|       biotech|[approved, invest...|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00005|       biotech|[approved, invest...|[DB01281, DB00026...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00006|small molecule|[approved, invest...|[DB06605, DB06695...|     false|             true|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00007|small molecule|[approved, invest...|[DB09066, DB09083...|     false|             true|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00008|       biotech|[approved, invest...|[DB06643, DB00005...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n",
       "df: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"withdrawn\", col(\"group\").contains(\"withdrawn\"))\n",
    "df = df.withColumn(\"illicit\", col(\"group\").contains(\"illicit\"))\n",
    "df = df.withColumn(\"vet_approved\", col(\"group\").contains(\"vet_approved\"))\n",
    "df = df.withColumn(\"investigational\", col(\"group\").contains(\"investigational'\"))\n",
    "df = df.withColumn(\"approved\", col(\"group\").contains(\"approved\"))\n",
    "df = df.withColumn(\"experimental\", col(\"group\").contains(\"experimental\"))\n",
    "df = df.withColumn(\"nutraceutical\", col(\"group\").contains(\"nutraceutical\"))\n",
    "df.show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Nodes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "|drug_id|          type|               group|        interactions|is_biotech|is_small_molecule|withdrawn|illicit|vet_approved|investigational|approved|experimental|nutraceutical|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "|DB00001|       biotech|          [approved]|[DB06605, DB06695...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00002|       biotech|          [approved]|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00003|       biotech|          [approved]|                null|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00004|       biotech|[approved, invest...|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00005|       biotech|[approved, invest...|[DB01281, DB00026...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00006|small molecule|[approved, invest...|[DB06605, DB06695...|     false|             true|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00007|small molecule|[approved, invest...|[DB09066, DB09083...|     false|             true|    false|  false|       false|          false|    true|       false|        false|\n",
      "|DB00008|       biotech|[approved, invest...|[DB06643, DB00005...|      true|            false|    false|  false|       false|          false|    true|       false|        false|\n",
      "+-------+--------------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// val df2 = df.withColumn(\"interactions\", explode(array(col(\"interactions\"))))\n",
    "// df2.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|drug_id|node_id|\n",
      "+-------+-------+\n",
      "|DB00194|      0|\n",
      "|DB00741|      1|\n",
      "|DB00846|      2|\n",
      "|DB00912|      3|\n",
      "|DB01357|      4|\n",
      "|DB01460|      5|\n",
      "|DB01979|      6|\n",
      "+-------+-------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df_drug_node_map: org.apache.spark.sql.DataFrame = [drug_id: string, node_id: string]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_drug_node_map = spark.read.options(Map(\"delimiter\"->\",\", \"header\"->\"true\"))\n",
    "  .csv(\"/home/jovyan/work/data/drug2NodeMap.csv\")\n",
    "df_drug_node_map.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: Long = 13608\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+-------+\n",
      "|drug_id|   type|               group|        interactions|is_biotech|is_small_molecule|withdrawn|illicit|vet_approved|investigational|approved|experimental|nutraceutical|node_id|\n",
      "+-------+-------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+-------+\n",
      "|DB00001|biotech|          [approved]|[DB06605, DB06695...|      true|            false|    false|  false|       false|          false|    true|       false|        false|   9529|\n",
      "|DB00002|biotech|          [approved]|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|   3685|\n",
      "|DB00003|biotech|          [approved]|                null|      true|            false|    false|  false|       false|          false|    true|       false|        false|   2938|\n",
      "|DB00004|biotech|[approved, invest...|[DB00012, DB00016...|      true|            false|    false|  false|       false|          false|    true|       false|        false|   6476|\n",
      "|DB00005|biotech|[approved, invest...|[DB01281, DB00026...|      true|            false|    false|  false|       false|          false|    true|       false|        false|   1028|\n",
      "+-------+-------+--------------------+--------------------+----------+-----------------+---------+-------+------------+---------------+--------+------------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "node_features: org.apache.spark.sql.DataFrame = [drug_id: string, type: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val node_features = df.join(df_drug_node_map, Seq(\"drug_id\"), \"left\")\n",
    "node_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res30: Long = 13608\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features\n",
    "   .repartition(1)\n",
    "   .write.format(\"com.databricks.spark.csv\")\n",
    "   .option(\"header\", \"true\")\n",
    "   .save(\"/home/jovyan/work/data/node_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
